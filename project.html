<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Danilo Lofaro" />


<title>PracticalMachineLearningProject</title>


<meta name="viewport" content="width=device-width, initial-scale=1" />

<style type="text/css">code{white-space: pre;}</style>

<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type="text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">PracticalMachineLearningProject</h1>
<h4 class="author"><em>Danilo Lofaro</em></h4>
<h4 class="date"><em>14 febbraio 2016</em></h4>
</div>


<div id="the-project" class="section level3">
<h3>The Project</h3>
<div id="background" class="section level4">
<h4>Background</h4>
<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.</p>
</div>
<div id="data" class="section level4">
<h4>Data</h4>
<p>The goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of the 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: [linked phrase](<a href="http://groupware.les.inf.puc-rio.br/har" class="uri">http://groupware.les.inf.puc-rio.br/har</a> (see the section on the Weight Lifting Exercise Dataset).</p>
<p>The training data for this project are available at <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">linked phrase</a></p>
<p>The test data are available at <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">linked phrase</a></p>
<p>The data for this project come from this source: <a href="http://groupware.les.inf.puc-rio.br/har">linked phrase</a></p>
</div>
<div id="goal" class="section level4">
<h4>Goal</h4>
<p>Goal of the project is to predict the manner in which the participants did the exercise. This is the “classe” variable in the training set, using any of the other variables to predict with. A report describing how the model is built, how cross validation was used, what is the expected out of sample error. The prediction model will be used to predict 20 different test cases.</p>
</div>
<div id="loading-getting-and-pre-processing-data" class="section level4">
<h4>Loading, Getting and Pre-processing data</h4>
<pre class="r"><code>set.seed(12345)

trainUrl &lt;- &quot;http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;
testUrl &lt;- &quot;http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;

training &lt;- read.csv(url(trainUrl), na.strings=c(&quot;NA&quot;,&quot;#DIV/0!&quot;,&quot;&quot;))
testing &lt;- read.csv(url(testUrl), na.strings=c(&quot;NA&quot;,&quot;#DIV/0!&quot;,&quot;&quot;))

dim(training)</code></pre>
<pre><code>## [1] 19622   160</code></pre>
<pre class="r"><code>dim(testing)</code></pre>
<pre><code>## [1]  20 160</code></pre>
<p><br> Backup of original data</p>
<pre class="r"><code>training_original &lt;- training
testing_original &lt;- testing</code></pre>
<p><br> Remove 1st (<code>ID</code>) variable</p>
<pre class="r"><code>training &lt;- training[,-1]</code></pre>
<p><br> Remove NearZeroVariance variables</p>
<pre class="r"><code>library(caret)

nzv &lt;- nearZeroVar(training, saveMetrics=TRUE)
training &lt;- training[,nzv$nzv==FALSE]</code></pre>
<p><br> Remove variables with &gt; 60% <code>NA</code> values</p>
<pre class="r"><code>training &lt;- training[,colSums(is.na(training))&lt;.4*NROW(training)]</code></pre>
<p><br> Partioning the training set into training and test datasets</p>
<pre class="r"><code>inTrain &lt;- createDataPartition(training$classe, p=0.6, list=FALSE)

myTraining &lt;- training[inTrain, ]
myTesting &lt;- training[-inTrain, ]

dim(myTraining)</code></pre>
<pre><code>## [1] 11776    58</code></pre>
<pre class="r"><code>dim(myTesting)</code></pre>
<pre><code>## [1] 7846   58</code></pre>
</div>
<div id="prediction-model" class="section level4">
<h4>Prediction Model</h4>
<p>Using the dataset <code>myTraining</code> and Linear SVM we create the prediction model. Since the time needed to run the model we will test a single prediction model.</p>
<pre class="r"><code>library(parallel)
library(doParallel)

cl &lt;- makeCluster(detectCores() - 1)
registerDoParallel(cl)

reg_Control &lt;- trainControl(&quot;cv&quot;, number = 5, verboseIter = TRUE)
    
fit &lt;- train(myTraining$classe ~ .,data = myTraining, method=&quot;svmLinear2&quot;, tuneLength = 3,preProc=c('scale','center'),trControl = reg_Control)</code></pre>
<pre><code>## Aggregating results
## Selecting tuning parameters
## Fitting cost = 1, gamma = 2 on full training set</code></pre>
<pre class="r"><code>stopCluster(cl)</code></pre>
<p>Accuracy Plot</p>
<pre class="r"><code>plot(fit)</code></pre>
<p><img src="data:image/png;base64,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" alt /></p>
<p>Confusion Matrix on <code>myTraining</code> set.</p>
<pre class="r"><code>predFit&lt;- predict(fit, myTraining)
confusionMatrix(predFit, myTraining$classe)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 3272  246   13    0    0
##          B   64 1903  140   13    0
##          C   12  130 1886  136    5
##          D    0    0   14 1688  103
##          E    0    0    1   93 2057
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9176          
##                  95% CI : (0.9125, 0.9225)
##     No Information Rate : 0.2843          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.8956          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9773   0.8350   0.9182   0.8746   0.9501
## Specificity            0.9693   0.9772   0.9709   0.9881   0.9902
## Pos Pred Value         0.9266   0.8976   0.8695   0.9352   0.9563
## Neg Pred Value         0.9908   0.9611   0.9825   0.9757   0.9888
## Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2779   0.1616   0.1602   0.1433   0.1747
## Detection Prevalence   0.2998   0.1800   0.1842   0.1533   0.1827
## Balanced Accuracy      0.9733   0.9061   0.9445   0.9314   0.9702</code></pre>
<p><br> Accuracy on <code>myTraining</code> set is aroung 90%. Check the performance on <code>myTesting</code></p>
<pre class="r"><code>predTest&lt;- predict(fit, myTesting)
confusionMatrix(predTest, myTesting$classe)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2170  152    8    0    0
##          B   52 1244   87    9    0
##          C   10  122 1257  100    5
##          D    0    0   16 1102   74
##          E    0    0    0   75 1363
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9095          
##                  95% CI : (0.9029, 0.9158)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.8854          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9722   0.8195   0.9189   0.8569   0.9452
## Specificity            0.9715   0.9766   0.9634   0.9863   0.9883
## Pos Pred Value         0.9313   0.8937   0.8414   0.9245   0.9478
## Neg Pred Value         0.9888   0.9575   0.9825   0.9723   0.9877
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2766   0.1586   0.1602   0.1405   0.1737
## Detection Prevalence   0.2970   0.1774   0.1904   0.1519   0.1833
## Balanced Accuracy      0.9719   0.8981   0.9411   0.9216   0.9668</code></pre>
<p><br> Accuracy on <code>myTesting</code> remain aroung 90%. Now let’s check the prediction on the 20 test cases</p>
<pre class="r"><code>predCases &lt;- predict(fit, testing)
predCases</code></pre>
<pre><code>##  [1] B A B A A E D B A B B C B A E E A B B B
## Levels: A B C D E</code></pre>
<p><br> #### Conclusions</p>
<p>The model predicted the 20 test cases with 100% accuracy. All 20 points were awarded after submitting the 20 test files.</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
